Formální systémy, logika 1. řádu, jazyk, axiomy, odvozovací pravidla.
- 1. řád: objekty a vztahy mezi objekty 
    - proměnné (spočetně mnoho)
    - funkční symboly 
    - relační/predikátové symboly 
    - kvantifikátory 
    - logické spojky 
    - ?sort of predikát? :: ekvivalence 

- Model / L-struktura: 
    - realizace relačních symbolů 
    - realizace funkčních symbolů 
    - universum A pro relační a funkční symboly 
    ~ výrokové proměnné: nulární relační symboly 
    ~ konstanty: nulární funkční symboly 

- Teorie jazyka: libovolná množina formulí T :: axiomů 
    - model teorie: L-struktura taková, že v dané struktuře platí všechny axiomy 

Výroková logika sémantika, tautologie a splnitelnost, dokazatelnost
- výroková logika: fakta platí / ne 
    - výrokové proměnné z P (prvkovýroky) :: spočetně
    - logické spojky
    - závorky

- odvozovací pravidla :: syntaktické vyplývání :: hilbertovský kalkulus 
    - axiomová schémata: fí => (pí => fí)
    - axiomová schémata: pí => (fí => psí) => (pí => fí) => (pí => psí) 
    - axiomová schémata: (!pí => !fí) => (fí => pí)

    - případně axiom substituce

    - inferenční pravidla: 
        - modus ponens: fí, fí=>psí / psí
        - pravidlo generalizace: fi => Vx fi

    -> důkaz je posloupnost formulí: a1, a2, a3, ...: ai
        - axiom 
        - formule z T
        - vznikla odvozením z předchozích formulí a1..ai-1

- sémantika: 
    - uvažujeme pouze dvouhodnotovou logiku 
    - prvovýroky odpovídají atomickým tvrzení s určeným významem 
    - sémantika logických spojek je dána pravdivostními tabulkami 

    - bool funkce: n-ární operace na [2]
    - hodnota výroku rekurzivně 

    - pro 1st order je sémantika daná modelem/strukturou 
    - má model pokud každá konečná podčást má model 

- tautologie a splnitelnost 
    - tautologie/pravidvost: platí v každém modelu jazyka
    - splnitelnost: platí v nějakém modelu jazyka  
    - dokazatelný: dá se (syntakticky) dokázat z Teorie 

    - dokazatelný -> platí: korektní 
    - platí -> dokazatelný: úplný 

Normální tvary formulí.
- literál: prvovýrok / negace 
- klazule: disjunkce literálů 
- CNF: konjukce klazulí 

- elementárních konjukce: konjukce literálů
- DNF: disjunkce elementárních konjukcí 

- převod tabulkou: 
    - DNF: získám model, disjunkce modelů 
    - CNF: z tabulky otočením and/or a negace doplňku modelu 

    -> každý výrok lze převést do CNF/DNF 

- skolemizace: zachovávává splnitelnost 
    - převedu všechny existenční kvantifikátory na funkce předchozích proměnných (co se týče pořadí kvantifikátorů)
    - vyvedu všechny universální kvantifikátory ven 

Strojové dokazování vět, model checking, dopředné a zpětné řetězení, rezoluční metoda a unifikace

- model checking 
    - AI1/lecture08.pdf 
    - lokální search, ~enumerace truth table

    - enumerace: zkoušeím všechny ohodnocení proměnných, kde je pravdivá knowledge base 
    - DPLL: baktracking na hodnotu proměnných + jednotková propagace (klazule s jedním literálem) + rizí propagace (pokud je jen pozitivní/negativní literál)
    - random SAT/max SAT: pravděpodobnostní algoritmy na SAT 
    - walkSAT: v cykle bere nesplněné klazule, buď v nich změní náhodný literál nebo takový, který minimalizuje počet nesplněných klazulí 

- inference rules 
    - theorem proving skrze inferenční pravidla 
    - rezoluce, tablo, ...

- rezoluce: stejně jako v logice :: CNF
    - rezoluční důkaz: klazule C z formule S na konci posloupnosti rezolvent předchozích Ci 
    - zamítnutí formule S: rezoluční důkaz [] z S

    - jde o zamítací proceduru, snaží se dokázat že daná formule / teorie je nesplnitelná
    - rezolvujeme Teorii + negaci -> chceme dojít ke sporu -> není tautologie, že neplatí -> musí být splnitelná 

    - rezolvuju dvě klazule s opačnými literály -> víme, že skrz danou proměnnou jde splnit jen jednu -> vztvořím novou bez dané proměnné 
    - korektní a úplná metoda 

    - rezoluce v 1st order 
        - přejmenuju na jiné proměnné, unifikuju rezolventy, rezolvuju

    - rezoluční strategie:
        - unit resoluce: preferujeme resoluční step s unit klazulí -> preference zkrácení klazulí
        - input-resolution: vždycky alespoń jedna klazule z vstupu (not complete)
        - subsumption: eliminace klazulí, které jsou subsumed (více specifické) než jiné z KB

- FOL to PL 
    - proměnné: grounding :: instanciate variables všemy možnými termy 
    - kvantifikátory: skolemizace  

    - Herbrand: Pokud existuje inference v FOL given KB, existuje inference v konečném (ale možná super-velkém) subsetu z plně instanciované PL

- tablo     
    - binární značkovací strom representující hledání protipříkladu proti pí (hledání modelu teorie, kde pí neplatí)
        - připojuju atomická tabla pro jednotlivé formule 
        - větve: or 
    - formule má důkaz pokud každá větev tabla selže 
    - pokud protipříklad existuje: v dokončeném tablu bude větev, která ho poskytuje (byť nekonečná)

- hornovská klazule 
    - klazule: obsahuje pouze jeden pozitivní literál 
    ~ odpovídá Prologu : fakta / pravidla 
        - syn(X, Y) :- otec(Y, X), muz(X) :: { syn(X, Y), !otec(Y, X), !muz(X) }
        - ...
    - LI rezoluce :: rezoluce nad hornovskými klazulemi 
    - forward chaining: 
        - ze známých faktů odvozujeme skrze Horn-clauses všechny možné důsledky dokud je možné / narazíme na query 
        - může být inkrementální: ber v potaz jen pravidla přidaná do KB v posledním kroce 
            - precomputed dependency network 
        - ~data driven  
    - backward chaining 
        - query je postupně rozložená na sub-queries, postupně se snažíme dokázat než se dostaneme k faktům z KB / teorie
        - not complete if implemented as DFS (can cycle)
        - ~goal driven

- unifikace
    - nechť S je konečná množina výrazů, p je nejlevější pozice kde se liší, neshoda: D(s) množina podvýrazů začínajících na p ze všech v S
    - je-li Sk singleton, vydej složenou substituci
    - zjisti zda v D(Sk) existuje proměnná x a term t neobsahující x 
        - NE: není unifikovatelná 
        - ANO: subst += {x/t}  
    -> vydá MGU, v každém kroku eliminuje jednu proměnnou 
    - x, f(x) not unifiable (check not done in Prolog)


Podmíněná nezávislost, Bayesovské sítě, výpočet v Bayesovské síti, naivní Bayesovský klasifikátor, 
- podmíněná nezávislost:
    - P(R and B | Y) = P(R|Y) * P(B|Y)
    - eq: P(R| B and Y) = P(R|Y)

- bayesovská síť 
    - also known as: belief network, probabilistic network, causal network, ...
    - DAG: 
        - node: odpovídá random variable (BUNO: binární)
        - obsahuje podmíněné prob. distribuci given parents P(X | parents(X))
        -> velikost: 2^|parents(X)|
    - celkově representuje plnohodnotnou full-joint probability 

    - tvorba bayesovské sítě 
        - identifikace relevantních proměnných 
        - seřazení proměnných Xi v pořadí 1...n 
            - pro každé i identifikuj minimální set parents(Xi), tak že: P(Xi | Parents(Xi)) = P(Xi | P1..Pi-1)
        - zapiš podmíněné pravděpodobnosti P(Xi | Parents(Xi))
        -> garantuje acykličnost 
        -> garantuje absenci redundance -> je konsistentní 

    - potenciálně výrazně kompaktnější než full-joint probability :: pokud je síť relativně sparse 
        - pokud každá var. influence by k parents n*2^k vs 2^n 
        - lze ignorovat jemné závislosti :: pruning 

        - zásadně záleží na pořadí proměnných z 1. construction kroku

    - podmíněná nezávislost 
        - node je podmíněně nezávislá na svých ne-potomcích given its parents 
        - node je podmíněně nezávislá na všech ostatních nodech given rodiče, děti, a rodiče dětí 

    - tvorba - víc: 
        - iterujeme prostor všech BN ~ prohledáváme jen třídy ekvivalence - essenciální grafy 
        - zvol strukturu, odhadni parametry, modifikuj (přidej nejslibnější hranu, uber nejzbitečnější), repeat until time runs out 

    - tvorba parametry: EM algoritmus 
        - tipni parametry, infer hidden variables, které neznáme, na základě parametrů known evidence
        - aktualizuj parametry na základě hidden variables 

- výpočet v Bayesovské síti: zjištění posterior pravděpodobnosti X 
    - P(X|e) = a * P(X,e) = a*sum_Y P(X, e, y) // a: 1/P(e), e: evidence, y: hidden variables 
    - P(x1, x2, ...) = TT_i P(xi | parents(xi))

    - inference enumerací 
        - chain rule rozpočítám viz výše -> odpovídá stromu -> některé cesty se opakují
        - for each val xi of X:
            - extend xi with e 
            - Q(xi) <- enumerate_all(vars[bn], e)
                - Y, rest <- first(vars)
                - Y has value in e: 
                    - YES: P(y | Pa(Y)) x enumerate_all(rest, e) 
                    - No: sum_y P(y | Pa(Y)) x enumerate_all(rest, {e, y}) 
                
    - variable elimination 
        - remember sub-results to not to have to recompute them 
        - sum out variable 

        - orders variables: na pořadí zásadně záleží 
        - foreach: var in vars 
            factors :- make-factor[var, e][factors] 
                - vem všechny tabulky co mají v doméně var
                - udělej kartézský součin
            if var hidden_variable, then factors :- sum-out(var, factors)
                - marginalizuj (summing out) var
                - else: vyfiltruj přípustné e
        - return normalize(pointwise(factors))

        - pořadí: 
            - dobré: první uzly bez dětí a evidence 
            - špatné: nejdřív nepozorované rodiče 

    - pokud je síť poly-tree (max. 1 neorientovaná cesta): O(n*d^k)
    - jinak NP hard 

    - aproximační inference 
        - direct sampling: 
            - každý sample generovaný přes pravděpodobnost z bayes network
            - topologický průchod: pravděpodobnost variable xi conditioned na již assigned parents(xi)
            - s N->inf P(x1, x2, ...) = N(x1, x2, ...)/N

            - rejection sampling: mazání vzorků nekonsistentních s evidence: dostáváme P(X|e)
            - likelyhood weighting: generuju jen přípustné, musím vážit šancí, že dostanu přípustný 
        - markov chain sampling 
            - vygeneruj náhodný konsistnetní example 
            - repeat
                - pro náhodnou variable X (mimo Evidence) vyber novou hodnotu given P(x | markov_blanket(X))
                - zvýším čítač aktuálního samplu += 1
            
- naivní Bayesovský klasifikátor 
    - pro každý atribut Ai máme podmíněnou pravděpodobnost P(Ai | C=k)
    - naivní: předpokládáme podmíněnou nezávislost given wanted class 

    - vychází z bayese P(Ck | x) = P(c) * P(x|c) / P(x) -> p(x) konstantní, nedůležité pro argmax 
    - predice: argmax_k P(C==k) * TT_i P(A = ai | C = k)
    ~ rozšíření na strom závislostí 

    - dá se snadno naučit z dat: poměr Xk v Ck 

rozhodovací grafy, markovské rozhodovací procesy
- rozhodovací strom :: PGM::idNovy.pdf
    - zobecnění baysovské sítě 
    - vrcholy: 
        - rozhodovací: statické :: Di
        - náhodné: pravděpodobnost pro každou možnou konfiguraci stavů :: Xi
        - listy s utilitou: výplata situaci definovanou cestou od kořene
    - hrany 
        - stejný význam jako v bayseovské síti 
        - do rozhodovacích z náhodných nesou informace 
    - předpoklad nezapomínání: když se rozhodne hodnota proměnné, nezapomene se 

    - maximalizujeme očekávanou hodnotu 
        - EU(d|e) = sum_x V(d, x, e) * P(X|d, e)    
    - vyhodnocujeme od listů, rekurzivně; v decision node vybereme nejvyšší expected children 
    - v kořeni dostaneme očekávaný zisk ideální strategie

- influenční diagram 
    - DAG 
    - rozhodovací, náhodné, uzly utility 
        - rozhodovací a náhodné uzly mají konečné množiny vzájemně se vylučujících stavů 
        - hrany do náhodných jako v BN 
        - hrany do rozhodovacích přinášejí informace o příslušných náh. veličinách 
            - ~ odpovídá časovému uspořádání: jedno rozhodnutí před druhým 

    - vyhodnocení:
        - vytvoříme rozhodovací strom a ten vyhodnotíme 
        - skrze pozorované veličiny vytvoříme pořadí rozhodovacích uzlů, dřívější musí být blíže kořeni 
            - pro rozhodovací uzel Di: nejdříve zadáme hodnoty pozorované před, pak vybereme d1 s nejvyšším exp. ziskem 

        - eliminace proměnných naproti časovému uspořádání
            - řětězové pravidlo ~ jako v BN given decisions: P(O | D1, D2, ...) = TT_XzO: P(X|pa(X))
        - optimální strategie pro Di given: I0 < D1 < I1 <...<: 
            - sigm(I0, D1, I1..Di-1,Ii-1) = argmaxDi Sum_Ii maxDi+1 ... maxDn P(U|D1...Dn)*V(U, D1, ... Dn)

- markovské rozhodovací procesy 
    - stavy S, akce A, počáteční stav s0, matice přechodu T(s, a, s')
        - markovovská podmínka: přechod stavu závisí na k (většinou 1) předchozích stavech 
        - k ekvivalentní 1 -> kartez soucin stavů 
    - výplata v každém stavu R(s), 
        - discount factor x konečný horizont 

    - strategie: chceme najít pi(s), která maximalizuje expected value: 
        - pi = argmax_pi E[ sum_t y^t R(st) | pi ]

        - nekonečný horizont: stacionarní strategie, nezáleží kolik již bylo / zbývá 
        - konečný horizont: ne-stacionarní, záleží kolik už hotových tahů / kolik zbývá do konce 

    ~ reinforcement learning setup 
    - iterace hodnot: 
        - foreach s in S:
            - U[s] <- R(s) + y*max_a sum_s' T(s, a, s')*U(s')
    - iterace strategie: vygenerování strategie s known užitkem 
        - until unchanged
        - for each state s in S do: 
            - if max_a sum_s' T(s, a, s')*U(s') > sum_s' T(s, pi(s), s')*U(s')
                - unchanged <- false 
                - pi(s) = argmax_a sum_s' T(s, a, s')*U(s')

zpětnovazebné učení
- ./1_4_2_HLAA_notes.txt :: Metody pro učení agentů; zpětnovazební učení, základní formy učení zvířat

částečně pozorovatelné markovské rozhodovací procesy, podmíněná markovská pole
- POMDP 
    - States, Actions, Observations 
    - Transition probabilities: T(si, a, sj) = P(sj | si, a)
    - Observation probabilities: O(zi, a, sj) = P(zi | sj, a) or P(zi | sj)
    - Rewards, discount factor, initial belief (observations)

    - bez přístupu k actual aktuálnímu stavu, pouze k observacím a vybraným akcím 
        - můžeme udržovat pravděpodobnostní belief distribuci přes stavy 
        - po provedení akce a získání observací musíme upravit 
            - b'(s') = a * P(e, s') sum_s( P(s' | s, a) * b(s) ) || e: evidence 

            - pi(b_t-1, a_t-1, zt) = sum_s' O(s', a_t-1, zt) T(s, a_t-1, s') b_t-1(s) / Pr(zt | b_t-1, a_t-1) 
    - markovská podmínka vůči b[elief]

    - lze redukovat na MDP s vícedimenzionálním spojitým stavovým stavem 
        - nahradíme (neznámý) stav belief statem

    - filtering: počítání posterior distribuce givne evidence up to date  
        - P(Xt | e1:t)
        - viz výše, forward 

    - prediction: P(Xt+k | e1:t)
    - smoothing: P(Xk | e1:k, ek:t)
        - backward: a f1:k x bk+1:t
        - pravděpodobnost stavu Xk given e1:k X pravděpodobnost evidence ek:t given stav Xk 

    - most likely sequence: nejpravděpodobnější cesta do stavu Xk se skládá z nejpravděpodobnější cesty do předchozího stavu + tranition to Xk -> iterativně

- podmíněná markovská pole 
    - MRF: Markov random field
        - neorientovaný graf, klidně s cykly 
        - definujeme podmnožiny proměnných a sílu jejich couplingu 

        - oblíbená faktorizace do klik 
            - p(x1, x2, ..., xn) = 1/Z IIc€C qc(xc) || C: množina klik v grafu, qc: faktor over proměnné v klice 
                - nemusí být přes všechny kliky
                - ignorujeme kliky velikosti 1

        - dobré např. na voting preferences skupiny lidí :: závislost ale ne jasná kauzalita, cykly

        - BN: MRF s klikami velikosti 2 a DAGem 

    - CRF: podmíněná markovská pole
        - http://ai.ms.mff.cuni.cz/~sui/sabata17.pdf
        - https://ermongroup.github.io/cs228-notes/representation/undirected/
        - https://people.cs.umass.edu/~mccallum/papers/crf-tutorial.pdf

        - P(y|x) = 1/Z(x) TT c€Cq_c(xc, yc)
            - můžeme mít kliky uvnitř xc i třeba jen yc 
            - např.: konsistence se vstupem + konsistence uvnitř výstupu (např. pro OCR pixely<>písmena, sousední písmena mezi sebou)
        - Z(x) sum y€Y TT c€Cq_c(xc, yc) 
        - nemá explicitní model P(x)

